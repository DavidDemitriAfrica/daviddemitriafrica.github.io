---
layout: default
title: "Research - David Demitri Africa"
---

<h1>Research</h1>

<p>Below is all my currently published research work. Each entry includes a link to the paper, a short summary, and some personal thoughts.</p>

<div class="research-entry">
    <h2><a href="https://doi.org/10.1063/5.0166785" target="_blank">Lag and Duration of Leaderâ€“Follower Relationships in Mixed Traffic Using Causal Inference</a></h2>
    <p><strong>Summary:</strong> This paper implements a causal inference approach to analyze leader-follower dynamics in an arterial road in Chennai, India. We quantify the temporal lag and duration of interactions using transfer entropy metrics.</p>
    <p><strong>My thoughts:</strong> This was my first paper. I learned a lot about how to write research in general from here, and in the future I think I would like to do more papers in this style-- analyzing some weird real world phenomenon with an interesting method. Published in Chaos.</p>
</div>

<div class="research-entry">
    <h2><a href="https://aclanthology.org/2025.acl-long.1509/" target="_blank">Batayan: A Filipino NLP benchmark for evaluating Large Language Models
</a></h2>
    <p><strong>Summary:</strong> This paper introduces Batayan, a benchmark to evaluate LLMs on NLP tasks in Filipino.</p>
    <p><strong>My thoughts:</strong> Most of the work here was in actually writing/re-translating the entries. Would be nice to do some in-depth error analysis ala 
Parser Showdown at the Wall Street Corral. Published in ACL 2025 Main Conference</p>
</div>

<div class="research-entry">
    <h2><a href="https://arxiv.org/abs/2506.22105" target="_blank">Identifying a Circuit for Verb Conjugation in GPT-2
</a></h2>
    <p><strong>Summary:</strong> Looking for a circuit in GPT-2 that does subject verb agreement. We find one, but it gets progressively larger as the SVA task gets more complicated.</p>
    <p><strong>My thoughts:</strong> Final project for L193: Explainable Artificial Intelligence. Thinking of a place to submit this.</p>
</div>

<div class="research-entry">
    <h2><a href="https://arxiv.org/abs/2506.23679" target="_blank">Learning Modular Exponentiation with Transformers
</a></h2>
    <p><strong>Summary:</strong> We teach a small 4-layer transformer modular exponentiation. PCA on embeddings doesn't show any clear structure, but we do find a cool example of grokking by multiples of moduli. Also, we find a small circuit that performs regular/normal exponentiation.</p>
    <p><strong>My thoughts:</strong> Final project for R252: Theory of Deep Learning. Thinking of a place to submit this.</p>
</div>

<div class="research-entry">
    <h2><a href="https://arxiv.org/abs/2508.02189">Learning Dynamics of Meta-Learning in Small Model Pretraining
</a></h2>
<p><strong>Summary:</strong> If you replace half of the steps in language model pretraining with a meta-task, what does the model learn? Model achieves better loss, improves the vanilla model's F1 on NER, and has this really interesting phase transition.</p>
<p><strong>My thoughts:</strong> This is one half of my MPhil thesis. Have submitted this to a workshop somewhere. Really proud of Figure 6 here.</p>
</div>

<div class="research-entry">
    <h2><a href="https://arxiv.org/abs/2509.02160">Meta-Pretraining for Zero-Shot Cross-Lingual Named Entity Recognition in Low-Resource Philippine Languages
</a></h2>
<p><strong>Summary:</strong> At what point in pretraining does meta-pretraining start to improve zero-shot cross-lingual named entity recognition (NER) in Filipino and Tagalog? If you fine-tune every checkpoint from pretraining step 0 to 6000, you find some actual reuse of knowledge from the model's backbone.</p>
<p><strong>My thoughts:</strong> This is the other half of my MPhil thesis. Have submitted this to a workshop somewhere. I think Figures 4 to 7 look nice.</p>
</div>

<div class="research-entry">
    <h2><a href="https://arxiv.org/abs/2509.10625">No Answer Needed: Predicting LLM Answer Accuracy from Question-Only Linear Probes
</a></h2>
<p><strong>Summary:</strong> Can we predict the accuracy of LLM answers using model internals, even before the answer is generated? We find that a simple linear probe on activations can achieve surprisingly good performance.</p>
<p><strong>My thoughts:</strong> Worked on this with MARS 2.0 people. Nice graphs.</p>
</div>

<style>
.research-entry {
    margin-bottom: 2em;
    padding-bottom: 1em;
    border-bottom: 1px solid #ccc;
}
</style>
